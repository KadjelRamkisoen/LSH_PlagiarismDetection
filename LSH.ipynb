{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import binascii\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "small_dataset = 'data/news_articles_small.csv'\n",
    "df_small_dataset = pd.read_csv(small_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Pre-process data:\n",
    "        1. convert all to lowercase\n",
    "        2. remove punctuation\n",
    "\"\"\"\n",
    "\n",
    "#Convert to lowercase.\n",
    "df_small_dataset['article'] = df_small_dataset['article'].str.lower()\n",
    "\n",
    "#Remove punctuation\n",
    "p = re.compile(r'[^\\w\\s]+')\n",
    "df_small_dataset['article'] = [p.sub('', x) for x in df_small_dataset['article'].tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Split each document in a list of words\n",
    "\n",
    "    small_dataset_split = [\n",
    "        [documentID, document_text]\n",
    "    ]\n",
    "\"\"\"\n",
    "\n",
    "small_dataset_split = []\n",
    "for idx, row in df_small_dataset.iterrows():\n",
    "    small_dataset_split.append([row[0], row[1].split()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    createShingles\n",
    "\n",
    "    To create the shingles for the articles in the dataframe\n",
    "    @:param small_dataset_split - The dataframe with the articles\n",
    "\"\"\"\n",
    "\n",
    "def createShingles(small_dataset_split):\n",
    "#Add shingles with ngram 4\n",
    "#Source: https://github.com/chrisjmccormick/MinHash/blob/master/runMinHashExample.py\n",
    "    shingledDocs = {}\n",
    "    docIds = []\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    totalShingles = 0\n",
    "    for docId, article in small_dataset_split:\n",
    "        shingles = set()\n",
    "        for i in range(0, len(article) - 3):\n",
    "            shingle = article[i]+ \" \" + article[i + 1] + \" \" + article[i + 2] + \" \" + article[i + 3]\n",
    "\n",
    "            crc =  binascii.crc32(shingle.encode()) & 0xffffffff\n",
    "            shingles.add(crc)\n",
    "\n",
    "        shingledDocs[docId]= shingles\n",
    "        docIds.append(docId)\n",
    "        totalShingles = totalShingles + (len(article) - 3)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Time spent: ', t1-t0)\n",
    "    return shingledDocs, docIds, totalShingles"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    randomHash\n",
    "\n",
    "    To create random hash functions\n",
    "    @:param value\n",
    "    @:param rand_value\n",
    "\"\"\"\n",
    "def randomHash(value, rand_value):\n",
    "#     return int.from_bytes(hashlib.md5(str(value).encode()).digest(), \"big\")\n",
    "    return binascii.crc32(value.to_bytes(32, \"little\")) ^ rand_value\n",
    "\n",
    "\"\"\"\n",
    "    randomList\n",
    "\n",
    "    To create random hash functions\n",
    "    @:param value\n",
    "    @:param seed\n",
    "\"\"\"\n",
    "def randomList(n, seed=10):\n",
    "    random.seed(10)\n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        r = random.getrandbits(32)\n",
    "        l.append(r)\n",
    "    return l\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent:  0.24709224700927734\n"
     ]
    }
   ],
   "source": [
    "shingledDocs, docIds, totalShingles = createShingles(small_dataset_split)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random hash functions...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating random hash functions...\")\n",
    "# Number of hash functions\n",
    "M = 5\n",
    "random_values = randomList(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent:  0.9816708564758301\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    MinHashing from shingles\n",
    "\"\"\"\n",
    "signatures = []\n",
    "t0 = time.time()\n",
    "for doc in docIds:\n",
    "    signature = []\n",
    "#     print(shingledDocs[doc])\n",
    "    for hash_fun in range(M):\n",
    "        min_value = 1e11\n",
    "        random_value = random_values[hash_fun]\n",
    "        # print(\"random_value \", random_value)\n",
    "        for shingle in shingledDocs[doc]:\n",
    "            hash_value = randomHash(shingle, random_value)\n",
    "#             print(\"shingle\", shingle)\n",
    "#             print(\"h_value \", hash_value)\n",
    "            if hash_value < min_value:\n",
    "                min_value = hash_value\n",
    "        signature.append(min_value)\n",
    "        # print(min_value, \" hash number: \", hash_fun, \" sign\", signature)\n",
    "    signatures.append(signature)\n",
    "    # print(signatures)\n",
    "\n",
    "t1= time.time()\n",
    "\n",
    "print('Time spent: ', t1-t0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    LSH\n",
    "\"\"\"\n",
    "from itertools import combinations\n",
    "\n",
    "class LSH:\n",
    "    buckets = []\n",
    "    counter = 0\n",
    "    def __init__(self, b):\n",
    "        self.b = b\n",
    "        for i in range(b):\n",
    "            self.buckets.append({})\n",
    "\n",
    "    def make_subvecs(self, signature):\n",
    "        l = len(signature)\n",
    "        assert l % self.b == 0\n",
    "        r = int(l / self.b)\n",
    "        # break signature into subvectors\n",
    "        subvecs = []\n",
    "        for i in range(0, l, r):\n",
    "            subvecs.append(signature[i:i+r])\n",
    "        return np.stack(subvecs)\n",
    "\n",
    "    def add_hash(self, signature):\n",
    "        subvecs = self.make_subvecs(signature).astype(str)\n",
    "        for i, subvec in enumerate(subvecs):\n",
    "            subvec = ','.join(subvec)\n",
    "            if subvec not in self.buckets[i].keys():\n",
    "                self.buckets[i][subvec] = []\n",
    "            self.buckets[i][subvec].append(self.counter)\n",
    "        self.counter += 1\n",
    "\n",
    "    def check_candidates(self):\n",
    "        candidates = []\n",
    "        for bucket_band in self.buckets:\n",
    "            keys = bucket_band.keys()\n",
    "            for bucket in keys:\n",
    "                hits = bucket_band[bucket]\n",
    "                if len(hits) > 1:\n",
    "                    candidates.extend(combinations(hits, 2))\n",
    "        return set(candidates)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "inverted_signs = []\n",
    "\n",
    "for i in range(len(signatures[0])):\n",
    "    invert = []\n",
    "    for signature in signatures:\n",
    "        invert.append(signature[0])\n",
    "    inverted_signs.append(invert)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "b = 5\n",
    "\n",
    "lsh = LSH(b)\n",
    "\n",
    "for signature in signatures:\n",
    "    lsh.add_hash(signature)\n",
    "\n",
    "candidate_pairs = lsh.check_candidates()\n",
    "len(candidate_pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "414"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def bandedCandidatePair(col1, col2, b, r):\n",
    "    \"\"\"Returns a boolean if the two columns are a candidate pair\n",
    "    inputs must obey n=len(col1)=len(col2)=b*r\"\"\"\n",
    "    n = len(col1)\n",
    "    assert(n==b*r)\n",
    "    assert(n==len(col2))\n",
    "    truth_array = (col1==col2)\n",
    "    return any(all(band) for band in np.array_split(truth_array,b))\n",
    "\n",
    "def bandedCandidatePairs(sig_mat, b, r):\n",
    "    d = sig_mat.shape[1]\n",
    "    idxs = range(d)\n",
    "    cols = [sig_mat[:,i] for i in range(d)]\n",
    "    pairs = set()\n",
    "    for (i,col1), (j,col2) in combinations(zip(idxs,cols),2):\n",
    "        if bandedCandidatePair(col1,col2,b,r):\n",
    "            pairs.add((i,j))\n",
    "    return pairs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "b=5\n",
    "r=1\n",
    "\n",
    "matrix = np.array(inverted_signs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "pairs = bandedCandidatePairs(matrix, b, r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "print(len(pairs))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-4c4f150c",
   "language": "python",
   "display_name": "PyCharm (LSH_PlagiarismDetection)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}