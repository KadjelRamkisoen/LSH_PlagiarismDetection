{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import binascii\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'data/news_articles_large.csv'\n",
    "df_dataset = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Pre-process data:\n",
    "        1. convert all to lowercase\n",
    "        2. remove punctuation\n",
    "\"\"\"\n",
    "\n",
    "#Convert to lowercase.\n",
    "df_dataset['article'] = df_dataset['article'].str.lower()\n",
    "\n",
    "#Remove punctuation\n",
    "p = re.compile(r'[^\\w\\s]+')\n",
    "df_dataset['article'] = [p.sub('', x) for x in df_dataset['article'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Split each document in a list of words\n",
    "\n",
    "    small_dataset_split = [\n",
    "        [documentID, document_text]\n",
    "    ]\n",
    "\"\"\"\n",
    "\n",
    "dataset_split = []\n",
    "for idx, row in df_dataset.iterrows():\n",
    "    dataset_split.append([row[0], row[1].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    createShingles\n",
    "\n",
    "    To create the shingles for the articles in the dataframe\n",
    "    @:param small_dataset_split - The dataframe with the articles\n",
    "\"\"\"\n",
    "\n",
    "def createShingles(small_dataset_split):\n",
    "#Add shingles with ngram 5\n",
    "#Source: https://github.com/chrisjmccormick/MinHash/blob/master/runMinHashExample.py\n",
    "    shingledDocs = {}\n",
    "    docIds = []\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    totalShingles = 0\n",
    "    for docId, article in small_dataset_split:\n",
    "        shingles = set()\n",
    "        for i in range(0, len(article) - 5):\n",
    "            shingle = article[i]+ \" \" + article[i + 1] + \" \" + article[i + 2] + \" \" + article[i + 3] + \" \" + article[i + 4] \n",
    "\n",
    "            crc =  binascii.crc32(shingle.encode()) & 0xffffffff\n",
    "            shingles.add(crc)\n",
    "\n",
    "        shingledDocs[docId]= shingles\n",
    "        docIds.append(docId)\n",
    "        totalShingles = totalShingles + (len(article) - 5)\n",
    "\n",
    "    t1 = time.time()\n",
    "    print('Time spent: ', t1-t0)\n",
    "    return shingledDocs, docIds, totalShingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    randomHash\n",
    "\n",
    "    To create random hash functions\n",
    "    @:param value\n",
    "    @:param rand_value\n",
    "\"\"\"\n",
    "def randomHash(value, rand_value):\n",
    "    return binascii.crc32(value.to_bytes(32, \"little\")) ^ rand_value\n",
    "\n",
    "\"\"\"\n",
    "    randomList\n",
    "\n",
    "    To create random hash functions\n",
    "    @:param value\n",
    "    @:param seed\n",
    "\"\"\"\n",
    "def randomList(n, seed=10):\n",
    "    random.seed(10)\n",
    "    l = []\n",
    "    for i in range(n):\n",
    "        r = random.getrandbits(32)\n",
    "        l.append(r)\n",
    "    return l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent:  4.267371892929077\n"
     ]
    }
   ],
   "source": [
    "shingledDocs, docIds, totalShingles = createShingles(dataset_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random hash functions...\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating random hash functions...\")\n",
    "# Number of hash functions\n",
    "M = 576\n",
    "random_values = randomList(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent:  1349.1122035980225\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    MinHashing from shingles\n",
    "\"\"\"\n",
    "signatures = []\n",
    "t0 = time.time()\n",
    "for doc in docIds:\n",
    "    signature = []\n",
    "    for hash_fun in range(M):\n",
    "        min_value = 0\n",
    "        random_value = random_values[hash_fun]\n",
    "        for shingle in shingledDocs[doc]:\n",
    "            hash_value = randomHash(shingle, random_value)\n",
    "            if hash_value < min_value or min_value == 0:\n",
    "                min_value = hash_value\n",
    "        \n",
    "        signature.append(min_value)\n",
    "    signatures.append(signature)\n",
    "\n",
    "t1= time.time()\n",
    "\n",
    "print('Time spent: ', t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Katerina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from numpy import long\n",
    "\n",
    "\"\"\"\n",
    "    LSH\n",
    "\"\"\"\n",
    "from itertools import combinations\n",
    "\n",
    "class LSH:\n",
    "    def __init__(self, b, r):\n",
    "        self.counter = 0\n",
    "        self.b = b\n",
    "        self.r = r\n",
    "        self.hash_tables= {}\n",
    "\n",
    "        self.create_hash_tables()\n",
    "\n",
    "    def create_hash_tables(self):\n",
    "        # The hash function must be (s1, s2, p1, p2) sensitive\n",
    "        # We need to have r hash functions\n",
    "        # Per band we have a hash table\n",
    "\n",
    "        # Add hash tables\n",
    "        for i in range(self.b):\n",
    "            self.hash_tables[i] = {}\n",
    "\n",
    "    def hash(self, i, subvec):\n",
    "        acc = \"\"\n",
    "        for value in subvec:\n",
    "            acc += str(int(float(value)))\n",
    "        return acc\n",
    "\n",
    "    def add_to_hash_table(self, i, subvec):\n",
    "        if subvec not in self.hash_tables[i]:\n",
    "            self.hash_tables[i][subvec] = []\n",
    "            self.hash_tables[i][subvec].append(self.counter)\n",
    "        else:\n",
    "            self.hash_tables[i][subvec].append(self.counter)\n",
    "\n",
    "    def make_subvecs(self, signature):\n",
    "        l = len(signature)\n",
    "        assert l % self.b == 0\n",
    "        r = self.r\n",
    "        # break signature into subvectors\n",
    "        subvecs = []\n",
    "        for i in range(0, l, r):\n",
    "            subvecs.append(signature[i:i+r])\n",
    "        return np.stack(subvecs)\n",
    "\n",
    "    def add_hash(self, signature):\n",
    "        subvecs = self.make_subvecs(signature).astype(str)\n",
    "        for i, subvec in enumerate(subvecs):\n",
    "            #Hash every subvector using another hash function\n",
    "            #and add it to a different hash table that corresponds\n",
    "            #to that hash function\n",
    "            hashed_subvec = self.hash(i+1, subvec)\n",
    "            self.add_to_hash_table(i, hashed_subvec)\n",
    "        self.counter += 1\n",
    "\n",
    "    def check_candidates(self):\n",
    "        candidates = []\n",
    "        for i in self.hash_tables:\n",
    "            keys = self.hash_tables[i].keys()\n",
    "            for bucket in keys:\n",
    "                hits = self.hash_tables[i][bucket]\n",
    "                if len(hits) > 1:\n",
    "                    candidates.extend(combinations(hits, 2))\n",
    "        return set(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidate pairs are 342\n",
      "time spent:  29.346665859222412\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "b = 96\n",
    "r = 6\n",
    "lsh = LSH(b,r)\n",
    "l = b * r\n",
    "for signature in signatures:\n",
    "    lsh.add_hash(signature[:l])\n",
    "\n",
    "candidate_pairs = lsh.check_candidates()\n",
    "print(f\"Number of candidate pairs are {len(candidate_pairs)}\")\n",
    "t1 = time.time()\n",
    "print(\"time spent: \", t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.DataFrame(list(candidate_pairs), columns=[\"doc1\", \"doc2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2062</td>\n",
       "      <td>5649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2435</td>\n",
       "      <td>8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3714</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1544</td>\n",
       "      <td>7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>725</td>\n",
       "      <td>5515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc1  doc2\n",
       "0  2062  5649\n",
       "1  2435  8217\n",
       "2  3714  5000\n",
       "3  1544  7730\n",
       "4   725  5515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.to_csv(\"final_pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
